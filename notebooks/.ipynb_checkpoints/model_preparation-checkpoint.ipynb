{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa66b6d9-683a-4354-952a-33c42d3467cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59821272-9f3f-408f-b527-992fb62a6222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[[-4.1455, -4.2570, -4.0270, -5.0624, -4.3884, -2.1269, -3.7215,\n",
      "          -3.5342, -2.4015, -5.1361, -2.4917, -1.8796, -4.5441, -3.2815,\n",
      "          -5.1629, -3.9480, -3.6000, -2.8740, -1.5599, -2.7841]],\n",
      "\n",
      "        [[-1.8115, -4.2609, -3.0433, -3.7907, -3.9055, -2.5105, -4.2691,\n",
      "          -3.8963, -3.5454, -4.7727, -4.1554, -3.0199, -2.1312, -1.9373,\n",
      "          -2.8760, -3.8173, -2.3889, -3.3369, -3.2298, -4.9946]]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "\n",
      "\n",
      "Targets: tensor([[14,  7,  1, 11,  2,  3, 19,  8, 17, 12, 11, 14,  5,  4, 13,  4, 10,  8,\n",
      "         14,  3, 12,  8, 12,  5, 15,  4, 14,  5,  9, 19]])\n",
      "Input lengths:\n",
      " tensor([50])\n",
      "Target lengths:\n",
      " tensor([21])\n"
     ]
    }
   ],
   "source": [
    "T = 50\n",
    "C = 20\n",
    "N = 1\n",
    "S = 30\n",
    "\n",
    "S_min = 10\n",
    "input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "print(\"Inputs:\", input[:2])\n",
    "\n",
    "target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n",
    "print(\"\\n\\nTargets:\", target[:2])\n",
    "\n",
    "input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "print(\"Input lengths:\\n\", input_lengths)\n",
    "\n",
    "target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)\n",
    "print(\"Target lengths:\\n\", target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca59d1f-7e79-4d4d-a4a5-04c1e2d34385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0387,  0.0007,  0.0008,  0.0003,  0.0006,  0.0057,  0.0012,\n",
       "           0.0014,  0.0043,  0.0003,  0.0039,  0.0073,  0.0005,  0.0018,\n",
       "          -0.0079,  0.0009,  0.0013,  0.0027,  0.0100,  0.0029]],\n",
       "\n",
       "        [[-0.0263,  0.0007,  0.0023,  0.0011,  0.0010,  0.0039,  0.0007,\n",
       "           0.0007,  0.0014,  0.0004,  0.0007,  0.0023,  0.0057,  0.0069,\n",
       "          -0.0106,  0.0010,  0.0044,  0.0017,  0.0019,  0.0003]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctc_loss = nn.CTCLoss()\n",
    "loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "loss.backward()\n",
    "input.grad[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8be60f-96c9-4025-8dac-b9f62f91c497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<blank>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3, ' ': 4, 'а': 5, 'б': 6, 'в': 7, 'г': 8, 'д': 9, 'е': 10, 'ж': 11, 'з': 12, 'и': 13, 'й': 14, 'к': 15, 'л': 16, 'м': 17, 'н': 18, 'о': 19, 'п': 20, 'р': 21, 'с': 22, 'т': 23, 'у': 24, 'ф': 25, 'х': 26, 'ц': 27, 'ч': 28, 'ш': 29, 'щ': 30, 'ь': 31, 'ю': 32, 'я': 33, 'є': 34, 'і': 35, 'ї': 36, 'ґ': 37}\n",
      "{0: '<blank>', 1: '<sos>', 2: '<eos>', 3: '<unk>', 4: ' ', 5: 'а', 6: 'б', 7: 'в', 8: 'г', 9: 'д', 10: 'е', 11: 'ж', 12: 'з', 13: 'и', 14: 'й', 15: 'к', 16: 'л', 17: 'м', 18: 'н', 19: 'о', 20: 'п', 21: 'р', 22: 'с', 23: 'т', 24: 'у', 25: 'ф', 26: 'х', 27: 'ц', 28: 'ч', 29: 'ш', 30: 'щ', 31: 'ь', 32: 'ю', 33: 'я', 34: 'є', 35: 'і', 36: 'ї', 37: 'ґ'}\n"
     ]
    }
   ],
   "source": [
    "extra_tokens = [\"<blank>\", \"<sos>\", \"<eos>\", \"<unk>\", \" \"]\n",
    "tokens = extra_tokens + ['а', 'б', 'в', 'г', 'д', \n",
    "        'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', \n",
    "        'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', \n",
    "        'х', 'ц', 'ч', 'ш', 'щ', 'ь', 'ю', 'я',\n",
    "        'є', 'і', 'ї', 'ґ']\n",
    "char_to_index = {c:i for i, c in enumerate(tokens)}\n",
    "index_to_char = {i:c for i, c in enumerate(tokens)}\n",
    "print(char_to_index)\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86c7d8c-a1f3-44e9-a370-48447b0a0b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence \n",
      "'Московитам дозволено створити свою державу а татарам чеченцям – ні Але це – расизм'\n",
      "to indeces:\n",
      "\n",
      "1 17 19 22 15 19 7 13 23 5 17 4 9 19 12 7 19 16 10 18 19 4 22 23 7 19 21 13 23 13 4 22 7 19 32 4 9 10 21 11 5 7 24 4 5 4 23 5 23 5 21 5 17 4 28 10 28 10 18 27 33 17 4 18 35 4 5 16 10 4 27 10 4 21 5 22 13 12 17 2 \n",
      "\n",
      "Sentence \n",
      "'Московитам дозволено створити свою державу а татарам чеченцям – ні Але це – расизм'\n",
      "from indeces to chars:\n",
      "\n",
      "<sos> м о с к о в и т а м   д о з в о л е н о   с т в о р и т и   с в о ю   д е р ж а в у   а   т а т а р а м   ч е ч е н ц я м   н і   а л е   ц е   р а с и з м <eos> "
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def remove_stop_signs(sentence):\n",
    "    stop_signs = string.punctuation + \"–—»«…“”’\"\n",
    "    for sign in stop_signs:\n",
    "        sentence = sentence.replace(sign, \"\")\n",
    "    return sentence\n",
    "\n",
    "def sentence_to_indeces(sentence, cti : dict):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        cti - char to index dictionary\n",
    "    \"\"\"\n",
    "    sent = remove_stop_signs(sentence)\n",
    "    sent = sent.lower()\n",
    "    sent = sent.split()\n",
    "    result = []\n",
    "    for word in sent:\n",
    "        for c in word:\n",
    "            result.append(cti.get(c, cti[\"<unk>\"]))\n",
    "        result.append(cti[\" \"])\n",
    "    result = result[:-1]\n",
    "    result = [cti[\"<sos>\"]] + result + [cti[\"<eos>\"]]\n",
    "    return result\n",
    "\n",
    "\n",
    "sent = \"Московитам дозволено створити свою державу а татарам чеченцям – ні Але це – расизм\"\n",
    "sent_to_idxs = sentence_to_indeces(sent, char_to_index)\n",
    "print(f\"Sentence \\n'{sent}'\\nto indeces:\\n\")\n",
    "for i in sent_to_idxs:\n",
    "    print(i, end=\" \")\n",
    "\n",
    "print(f\"\\n\\nSentence \\n'{sent}'\\nfrom indeces to chars:\\n\")\n",
    "for i in sent_to_idxs:\n",
    "    print(index_to_char[i], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb4b99c-d8a2-44a7-b16c-6bee91f642c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"D:\\\\ML\\\\Speech recognition\\\\NLP_diploma\\\\uk\"\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436b932a-c5ec-4ef0-914d-965cb9b11790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max symbols 137\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "is_show_prints = False\n",
    "for sent in train_df[\"sentence\"]:\n",
    "    sent_to_idxs = sentence_to_indeces(sent, char_to_index)\n",
    "    if len(sent_to_idxs) > max:\n",
    "        max = len(sent_to_idxs)    \n",
    "    \n",
    "    if is_show_prints:\n",
    "        print(f\"Sentence \\n'{sent}'\\nto indeces:\")\n",
    "        for i in sent_to_idxs:\n",
    "            print(i, end=\" \")\n",
    "        print(f\"\\n\\nfrom indeces to chars:\")\n",
    "        for i in sent_to_idxs:\n",
    "            print(index_to_char[i], end=\" \")\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        \n",
    "print(f\"Max symbols {max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b787ba5-da22-4a74-b748-6f9f1d8ded9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 152)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens), 152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a41aafa1-e953-4fb1-96d9-552c9d5a7ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER PARAMS\n",
    "# Encoder inputs\n",
    "enc_n_feats = 256   # spectrogram height\n",
    "enc_d_model = 1024  # spectrogram max width\n",
    "\n",
    "# DECODER PARAMS\n",
    "# Decoder inputs\n",
    "dec_n_feats = 38    # len(tokens)\n",
    "dec_d_model = 152   # maximum symbols in sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a1e4bf1-1291-4d52-9d2c-131a1788b5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic: 'Московитам дозволено створити свою державу а татарам чеченцям – ні Але це – расизм'\n",
      "idxs_to_onehot result:\n",
      "(80, 38)\n",
      "\n",
      "onehot_matrix_to_idxs result:\n",
      "<sos> м о с к о в и т а м   д о з в о л е н о   с т в о р и т и   с в о ю   д е р ж а в у   а   т а т а р а м   ч е ч е н ц я м   н і   а л е   ц е   р а с и з м <eos> "
     ]
    }
   ],
   "source": [
    "def idxs_to_onehot(sent_idxs, length:int):\n",
    "    result = []\n",
    "    for number in sent_idxs:\n",
    "        onehot = np.zeros((length,))\n",
    "        onehot[number] = 1\n",
    "        result.append(onehot)\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "def onehot_matrix_to_idxs(onehots):\n",
    "    result = []\n",
    "    for i in range(onehots.shape[0]):\n",
    "        onehot = onehots[i, :]\n",
    "        number = np.argmax(onehot)\n",
    "        result.append(number)\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "sent = \"Московитам дозволено створити свою державу а татарам чеченцям – ні Але це – расизм\"\n",
    "print(f\"Basic: '{sent}'\")\n",
    "\n",
    "sent_to_idxs = sentence_to_indeces(sent, char_to_index)\n",
    "a = idxs_to_onehot(sent_to_idxs, dec_n_feats)\n",
    "print(\"idxs_to_onehot result:\")\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n",
    "print(\"\\nonehot_matrix_to_idxs result:\")\n",
    "r = onehot_matrix_to_idxs(a)\n",
    "for i in r:\n",
    "    print(index_to_char[i], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc699f-bba9-494a-b2be-e851745245a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

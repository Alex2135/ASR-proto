{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2b676d-5787-414d-8530-878ba4523aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e1ebed3-aa7a-43af-9de8-fbf2b57dab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * x.sigmoid()\n",
    "\n",
    "# YEP\n",
    "class EncoderInputsProc(nn.Module):\n",
    "    def __init__(self, d_inputs, d_model, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv1d(d_inputs, 256, kernel_size=7, stride=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, d_model, kernel_size=7, stride=3),\n",
    "            nn.ReLU()\n",
    "        ).to(device)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = X.transpose(-1, -2).contiguous()\n",
    "        out = self.convs(out)\n",
    "        out = out.transpose(-1, -2).contiguous()\n",
    "        return out\n",
    "\n",
    "# YEP\n",
    "class DecoderInputsProc(nn.Module):\n",
    "    def __init__(self, d_inputs, d_model, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(d_inputs, d_model),\n",
    "            nn.ReLU()\n",
    "        ).to(device)\n",
    "                \n",
    "    def forward(self, X):\n",
    "        out = self.lin(X)\n",
    "        return out\n",
    "    \n",
    "# YEP\n",
    "class AbsolutePositionEncoding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def pos_f(self, row, column, emb_dim):\n",
    "        func = (np.sin, np.cos)[column % 2]\n",
    "        w_k = 1/np.power(10000, 2*column/emb_dim)\n",
    "        pe_i_j = func(row * w_k)\n",
    "        return torch.Tensor([pe_i_j])\n",
    "    \n",
    "    def position_encoding(self, X):\n",
    "        assert len(X.shape) >= 3, \"X shape must have more then 3 dimension\"\n",
    "        b = X.shape[0]\n",
    "        h = X.shape[-2]\n",
    "        w = X.shape[-1]\n",
    "        pe = torch.zeros((b, h, w))\n",
    "        for k in range(b):\n",
    "            for i in range(h):\n",
    "                for j in range(w):\n",
    "                    pe[k][i][j] = self.pos_f(i, j, h)\n",
    "                \n",
    "        pe = pe.reshape(b, h, w)\n",
    "        return pe\n",
    "    \n",
    "    def forward(self, x):\n",
    "        PE = self.position_encoding(x)\n",
    "        return PE\n",
    "\n",
    "\n",
    "# YEP\n",
    "class LFFN(nn.Module):\n",
    "    def __init__(self, dim, dim_bn, dim_hid):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        dim_bn - int,\n",
    "            bottleneck dimention\n",
    "        dim - int,\n",
    "            dim of input data\n",
    "        dim_hid - int,\n",
    "            number of hidden units\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.E1 = nn.Linear(in_features=dim, out_features=dim_bn, bias=False)\n",
    "        self.D1 = nn.Linear(in_features=dim_bn, out_features=dim_hid, bias=False)\n",
    "        self.swish = Swish()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.E2 = nn.Linear(in_features=dim_hid, out_features=dim_bn, bias=False)\n",
    "        self.D2 = nn.Linear(in_features=dim_bn, out_features=dim, bias=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.E1(inputs)\n",
    "        x = self.D1(x)\n",
    "        x = self.swish(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.E2(x)\n",
    "        y = self.D2(x)\n",
    "        return y\n",
    "\n",
    "# YEP\n",
    "class MHLA2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_heads,\n",
    "                 dim_input_q,\n",
    "                 dim_input_kv,\n",
    "                 device=\"cpu\",\n",
    "                 mask=False\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert dim_input_q % num_heads == 0, \"dim_input_q must be devided on num_heads\"\n",
    "        assert dim_input_kv % num_heads == 0, \"dim_input_kv must be devided on num_heads\"\n",
    "        dim_q = dim_input_q // num_heads\n",
    "        dim_k = dim_input_kv // num_heads\n",
    "        self.device = device\n",
    "        self.with_mask = mask\n",
    "        self.W_Q = torch.ones((num_heads, dim_input_q, dim_q), device=device, requires_grad=True)\n",
    "        self.W_K = torch.ones((num_heads, dim_input_kv, dim_q), device=device, requires_grad=True)\n",
    "        self.W_V = torch.ones((num_heads, dim_input_kv, dim_q), device=device, requires_grad=True)\n",
    "        self.W_O = nn.Linear(dim_k * num_heads, dim_k * num_heads, bias=False)\n",
    "        self.W_Q = nn.init.xavier_uniform_(self.W_Q)\n",
    "        self.W_K = nn.init.xavier_uniform_(self.W_K)\n",
    "        self.W_V = nn.init.xavier_uniform_(self.W_V)\n",
    "        self.d_q = torch.pow(torch.Tensor([dim_q]).to(device), 1 / 4)\n",
    "        self.d_k = torch.pow(torch.Tensor([dim_k]).to(device), 1 / 4)\n",
    "        self.softmax_col = nn.Softmax(dim=-1)\n",
    "        self.softmax_row = nn.Softmax(dim=-2)\n",
    "\n",
    "    def mask(self, dim: (int, int)) -> Tensor:\n",
    "        a, b = dim\n",
    "        mask = torch.ones(b, a)\n",
    "        mask = torch.triu(mask, diagonal=0)\n",
    "        mask = torch.log(mask.T)\n",
    "        return mask.to(self.device)\n",
    "\n",
    "    def forward(self, x_q, x_k, x_v):\n",
    "        x_q, x_k, x_v = x_q.unsqueeze(dim=1), x_k.unsqueeze(dim=1), x_v.unsqueeze(dim=1)\n",
    "        print(f\"{self.W_Q.shape=}\")\n",
    "        print(f\"{x_q.shape=}\")\n",
    "        Q = torch.matmul(x_q, self.W_Q)\n",
    "        K = torch.matmul(x_k, self.W_K)\n",
    "        V = torch.matmul(x_v, self.W_V)\n",
    "        if self.with_mask == True:\n",
    "            Q += self.mask(Q.shape[-2:])\n",
    "        A = torch.matmul(self.softmax_col(K.transpose(-1, -2).contiguous() / self.d_k), V)\n",
    "        B = torch.matmul(self.softmax_row(Q / self.d_q), A)\n",
    "        #print(f\"{B.shape}\")\n",
    "        b, h, w, d = B.shape\n",
    "        B = self.W_O(B.view(b, w, h * d))\n",
    "\n",
    "        return B\n",
    "\n",
    "# YEP\n",
    "class GLU(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, gate = x.chunk(2, dim=self.dim)\n",
    "        return out * gate.sigmoid()\n",
    "\n",
    "# YEP\n",
    "class DepthWiseConv1d(nn.Module):\n",
    "    def __init__(self, chan_in, chan_out, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(chan_in, chan_in, kernel_size=(1, kernel_size), padding=(0, padding))\n",
    "        self.conv2 = nn.Conv2d(chan_in, chan_out, kernel_size=(1, 1))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "# YEP\n",
    "class PointWiseConv(nn.Module):\n",
    "    def __init__(self, chan_in):\n",
    "        super().__init__()\n",
    "        self.pw_conv = nn.Conv2d(in_channels=chan_in, out_channels=1, kernel_size=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.pw_conv(inputs)\n",
    "        return x\n",
    "\n",
    "# YEP\n",
    "class ConvModule(nn.Module):\n",
    "    def __init__(self, dim_W, dim_bn, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(dim_W)\n",
    "        self.pw_conv1 = PointWiseConv(chan_in=1)\n",
    "        self.glu = GLU(dim=-1)\n",
    "        self.dw_conv1d = DepthWiseConv1d(1, dim_bn, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(dim_bn)\n",
    "        self.swish = Swish()\n",
    "        self.pw_conv2 = PointWiseConv(chan_in=dim_bn)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs.unsqueeze(dim=1)\n",
    "\n",
    "        x = self.ln1(x)\n",
    "\n",
    "        x = self.pw_conv1(x)\n",
    "        x = self.glu(x)\n",
    "        x = self.dw_conv1d(x)\n",
    "\n",
    "        x = self.bn(x)\n",
    "        x = self.swish(x)\n",
    "        x = self.pw_conv2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = inputs.squeeze(dim=1)\n",
    "        return x\n",
    "\n",
    "# YEP\n",
    "class LAC(nn.Module):\n",
    "    def __init__(self, d_model, n_heads=2, device=\"cpu\", dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.lffn1 = LFFN(dim=d_model, dim_bn=256, dim_hid=1024)\n",
    "        self.do1 = nn.Dropout(dropout)\n",
    "        self.mhlsa = MHLA2(num_heads=n_heads, dim_input_q=d_model, dim_input_kv=d_model, device=device)\n",
    "        self.do2 = nn.Dropout(dropout)\n",
    "        self.conv_module = ConvModule(d_model, dim_bn=8)\n",
    "        self.do3 = nn.Dropout(dropout)\n",
    "        self.lffn2 = LFFN(dim=d_model, dim_bn=256, dim_hid=1024)\n",
    "        self.do4 = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = x + 1 / 2 * self.do1(self.lffn1(x))\n",
    "        x = x + self.do2(self.mhlsa(x, x, x))\n",
    "        x = x + self.do3(self.conv_module(x))\n",
    "        x = x + 1 / 2 * self.do4(self.lffn2(x))\n",
    "        x = self.ln(x)\n",
    "        return inputs + x\n",
    "\n",
    "# YEP\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, n_encoders=2, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.lacs = nn.Sequential(*[LAC(d_model=d_model, device=device) for i in range(n_encoders)])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.lacs(inputs)\n",
    "        return x\n",
    "\n",
    "\n",
    "# YEP\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, dim_tgt, dim_mem, device=\"cpu\", dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.mhla_with_mask = MHLA2(num_heads=2, dim_input_q=dim_tgt, dim_input_kv=dim_tgt, mask=True, device=device)\n",
    "        self.do1 = nn.Dropout(dropout)\n",
    "        self.ln1 = nn.LayerNorm(dim_tgt)\n",
    "        self.mhla_with_memory = MHLA2(num_heads=2, dim_input_q=dim_tgt, dim_input_kv=dim_mem, device=device)\n",
    "        self.do2 = nn.Dropout(dropout)\n",
    "        self.ln2 = nn.LayerNorm(dim_tgt)\n",
    "        self.lffn = LFFN(dim=dim_mem, dim_bn=256, dim_hid=1024)\n",
    "        self.do3 = nn.Dropout(dropout)\n",
    "        self.ln3 = nn.LayerNorm(dim_tgt)\n",
    "\n",
    "    def forward(self, mem, y):\n",
    "        y = y + self.do1(self.mhla_with_mask(y, y, y))\n",
    "        y = self.ln1(y)\n",
    "        y = y + self.do2(self.mhla_with_memory(y, mem, mem))\n",
    "        y = self.ln2(y)\n",
    "        y = y + self.do3(self.lffn(y))\n",
    "        y = self.ln3(y)\n",
    "        return y\n",
    "    \n",
    "\n",
    "# YEP\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.3, device=\"cpu\", n_decoders=4):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.dec_blocks = nn.ModuleList([\n",
    "            DecoderBlock(dim_tgt=d_model, dim_mem=d_model, device=device)\n",
    "            for _ in range(n_decoders)])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, 38).to(device),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, mem, tgt):\n",
    "        y = tgt.to(self.device)\n",
    "        print(f\"{y.shape=}\")\n",
    "\n",
    "        for dec in self.dec_blocks:\n",
    "            y = dec(mem, y)\n",
    "\n",
    "        y = self.classifier(y)\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "115c2cef-47fd-4e75-89aa-9740996d17b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model X1.shape=torch.Size([1, 206, 768])\n",
      "Model X2.shape=torch.Size([2, 1024, 768])\n",
      "PE torch.Size([2, 112, 64])\n",
      "X + PE out.shape=torch.Size([2, 112, 64])\n",
      "lffn out.shape=torch.Size([2, 112, 64])\n",
      "self.W_Q.shape=torch.Size([2, 64, 32])\n",
      "x_q.shape=torch.Size([2, 1, 112, 64])\n",
      "mhla2 out.shape=torch.Size([2, 112, 64])\n",
      "conv_m out.shape=torch.Size([2, 112, 64])\n",
      "self.W_Q.shape=torch.Size([2, 64, 32])\n",
      "x_q.shape=torch.Size([2, 1, 112, 64])\n",
      "lac out.shape=torch.Size([2, 112, 64])\n",
      "self.W_Q.shape=torch.Size([2, 64, 32])\n",
      "x_q.shape=torch.Size([2, 1, 112, 64])\n",
      "self.W_Q.shape=torch.Size([2, 64, 32])\n",
      "x_q.shape=torch.Size([2, 1, 112, 64])\n",
      "enc out.shape=torch.Size([2, 112, 64])\n",
      "enc_out.shape=torch.Size([2, 112, 64])\n",
      "X2.shape=torch.Size([2, 1024, 768])\n",
      "out.shape == X2.shape is False\n",
      "self.W_Q.shape=torch.Size([2, 64, 32])\n",
      "x_q.shape=torch.Size([2, 1, 151, 64])\n",
      "self.W_Q.shape=torch.Size([2, 64, 32])\n",
      "x_q.shape=torch.Size([2, 1, 151, 64])\n",
      "dec_b out.shape=torch.Size([2, 151, 64])\n",
      "y.shape=torch.Size([2, 151, 38])\n",
      "self.W_Q.shape=torch.Size([2, 64, 32])\n",
      "x_q.shape=torch.Size([2, 1, 151, 38])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected batch2_sizes[0] == bs && batch2_sizes[1] == contraction_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18016/4106955355.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[0mdec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# YEP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menc_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"dec {out.shape=}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ml\\speech recognition\\nlp_diploma\\asr proto\\asr proto\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18016/3944527197.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, mem, tgt)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdec_blocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ml\\speech recognition\\nlp_diploma\\asr proto\\asr proto\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18016/3944527197.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, mem, y)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmhla_with_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmhla_with_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ml\\speech recognition\\nlp_diploma\\asr proto\\asr proto\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18016/3944527197.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_q, x_k, x_v)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.W_Q.shape=}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{x_q.shape=}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_q\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_Q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_K\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW_V\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected batch2_sizes[0] == bs && batch2_sizes[1] == contraction_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    }
   ],
   "source": [
    "def show_matrix(matrix: torch.Tensor, caption):\n",
    "    print(caption)\n",
    "    b, c, w, h = matrix.shape\n",
    "    m = matrix.reshape(w, h)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.ylabel(\"position\")\n",
    "    plt.xlabel(\"dim\")\n",
    "    plt.imshow(m.detach().numpy(), origin='lower')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class Conformer(nn.Module):\n",
    "    def __init__(self, n_encoders=2, n_decoders=2, d_model=64, device=\"cpu\", dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.enc_proc = EncoderInputsProc(d_inputs=768, d_model=d_model, device=device)\n",
    "        self.dec_proc = DecoderInputsProc(d_inputs=38, d_model=d_model, device=device)\n",
    "        self.pos_enc_inp = AbsolutePositionEncoding()\n",
    "        self.pos_enc_out = AbsolutePositionEncoding()\n",
    "        self.encoder = Encoder(n_encoders=n_encoders, d_model=64, device=device)\n",
    "        self.decoder = Decoder(n_decoders=n_decoders, d_model=64, device=device)\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "\n",
    "    def to(self, device, *args, **kwargs):\n",
    "        self = super().to(device, *args, **kwargs)\n",
    "        self.device = device\n",
    "        return self\n",
    "\n",
    "    def forward(self, inputs, tgt):\n",
    "        x = self.enc_proc(inputs)\n",
    "        x = x + self.pos_enc_inp(x).to(self.device)\n",
    "        x = self.encoder(x)        \n",
    "        y = self.dec_proc(tgt)\n",
    "        y = y + self.pos_enc_out(y).to(self.device)\n",
    "        y = self.decoder(x, y)\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    \n",
    "d_model = 64\n",
    "    \n",
    "X1 = torch.randn(1, 206, 768) #X1 = torch.randn(1, 768, 206)\n",
    "X2 = torch.randn(2, 1024, 768) #X2 = torch.randn(2, 768, 1024)\n",
    "\n",
    "Y1 = torch.randn(1, 29, 38)\n",
    "Y2 = torch.randn(2, 151, 38)\n",
    "\n",
    "enc_proc = EncoderInputsProc(768, d_model) # YEP\n",
    "X1_p = enc_proc(X1)\n",
    "X2_p = enc_proc(X2)\n",
    "\n",
    "dec_proc = DecoderInputsProc(38, d_model) # YEP\n",
    "Y1_p = dec_proc(Y1)\n",
    "Y2_p = dec_proc(Y2)\n",
    "\n",
    "print(f\"Model {X1.shape=}\")\n",
    "print(f\"Model {X2.shape=}\")\n",
    "tgt = Y2_p\n",
    "out = X2_p\n",
    "APE = AbsolutePositionEncoding() # YEP\n",
    "PE = APE(out)\n",
    "out = out + PE\n",
    "print(f\"PE {PE.shape}\")\n",
    "print(f\"X + PE {out.shape=}\")\n",
    "lffn = LFFN(dim=d_model, dim_bn=256, dim_hid=1024) # YEP\n",
    "out = lffn(out)\n",
    "print(f\"lffn {out.shape=}\")\n",
    "\n",
    "mhla2 = MHLA2(num_heads=2, dim_input_q=d_model, dim_input_kv=d_model) # YEP\n",
    "out = mhla2(out, out, out)\n",
    "print(f\"mhla2 {out.shape=}\")\n",
    "\n",
    "conv_m = ConvModule(d_model, dim_bn=8) # YEP\n",
    "out = conv_m(out)\n",
    "print(f\"conv_m {out.shape=}\")\n",
    "\n",
    "lac = LAC(d_model) # YEP\n",
    "out = lac(out)\n",
    "print(f\"lac {out.shape=}\")\n",
    "\n",
    "enc = Encoder(d_model) # YEP\n",
    "enc_out = enc(out)\n",
    "print(f\"enc {out.shape=}\")\n",
    "\n",
    "print(f\"{enc_out.shape=}\")\n",
    "print(f\"{X2.shape=}\")\n",
    "print(\"out.shape == X2.shape is\", out.shape == X2.shape)\n",
    "\n",
    "dec_b = DecoderBlock(dim_tgt=d_model, dim_mem=d_model) # YEP\n",
    "out = dec_b(mem=out, y=tgt)\n",
    "print(f\"dec_b {out.shape=}\")\n",
    "\n",
    "dec = Decoder(d_model=d_model) # YEP\n",
    "out = dec(mem=enc_out, tgt=Y2)\n",
    "print(f\"dec {out.shape=}\")\n",
    "\n",
    "conf = Conformer(d_model=d_model)\n",
    "emb, out = conf(inputs=X2, tgt=Y2)\n",
    "\n",
    "out.shape == Y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "419c2977-ed3b-43b4-aaec-8470497421f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.210526315789473\n"
     ]
    }
   ],
   "source": [
    "d_model = 768\n",
    "d_tgt = 38\n",
    "\n",
    "print(d_model/d_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffa0c362-0ebb-4afc-9d02-6083d484d277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 21])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(1, 768, 206)\n",
    "conv1 = nn.Conv1d(768, 256, kernel_size=7, stride=3)\n",
    "conv2 = nn.Conv1d(256, 64, kernel_size=7, stride=3)\n",
    "out = conv1(X)\n",
    "out = conv2(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "611f4838-f983-411a-94f3-639827f6776f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0476190476190474, 3.7281553398058254)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64/21, 768/206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf8a5d-9ca7-4ee6-aced-02224aaf0dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

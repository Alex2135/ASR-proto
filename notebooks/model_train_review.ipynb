{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5684ef0-3bdc-42ae-820a-a6addd88c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc3403a2-fed6-4cad-b830-1492a5613fc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'d_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9120/1542963176.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9120/1542963176.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[0mtgt_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m152\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_encoders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"n_encoders\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_decoders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"n_decoders\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mCONFIG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pretrain\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mPATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_1.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\Speech recognition\\NLP_diploma\\ASR proto\\ASR proto\\model\\efficient_conformer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"device\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         self.lin_out = nn.Sequential(\n\u001b[1;32m--> 337\u001b[1;33m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"d_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m38\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'd_model'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "\n",
    "from config import *\n",
    "from data_processing import ukr_lang_chars_handle\n",
    "from data_processing import CommonVoiceUkr\n",
    "from model import EfConfRecognizer as Model\n",
    "from model import get_cosine_schedule_with_warmup, OneCycleLR\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, optimizer, device, scheduler=None, epoch=1, wb=None):\n",
    "    print(f\"Training begin\")\n",
    "    model.train()\n",
    "    ctc_criterion = nn.CTCLoss(blank=ukr_lang_chars_handle.token_to_index[\"<blank>\"], zero_infinity=True)\n",
    "    running_loss = []\n",
    "    losses_per_phase = []\n",
    "\n",
    "    for idx, (X, tgt) in tqdm(enumerate(train_dataloader)):\n",
    "        tgt_text = \" \"#tgt[\"text\"]\n",
    "        tgt_class = tgt[\"label\"].long().to(device)\n",
    "        tgt_class = F.one_hot(tgt_class, num_classes=5)\n",
    "\n",
    "        one_hots = ukr_lang_chars_handle.sentences_to_one_hots(tgt_text, 152).to(device)\n",
    "        X = X.to(device) #\n",
    "\n",
    "        emb, output = model(X, one_hots)  # (batch, _, n_class, time), (batch, _, time, n_class)\n",
    "        loss = ce_criterion(output, tgt_class.float()) # output.shape == (N, C) where N - batch, C - number of classes\n",
    "        if wb:\n",
    "            wb.log({\n",
    "                \"loss\": loss.item(),\n",
    "                \"epoch\": epoch\n",
    "            })\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        running_loss.append(loss.cpu().detach().numpy())\n",
    "        losses_per_phase.append(loss.cpu().detach().numpy())\n",
    "        if (idx + 1) % 25 == 0:  # print every 200 mini-batches\n",
    "            loss_mean = np.mean(np.array(losses_per_phase))\n",
    "            print(f\"Epoch: {epoch}, Last loss: {loss.item():.4f}, Loss phase mean: {loss_mean:.4f}\")\n",
    "            if wb:\n",
    "                wb.log({\"loss phase mean\": loss_mean})\n",
    "            losses_per_phase = []\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "def val(model, train_dataloader, device, epoch, wb=None):\n",
    "    model.eval()\n",
    "    positive = 0\n",
    "    train_len = train_dataloader.sampler.num_samples\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"Evaluation on train dataset\")\n",
    "    with torch.no_grad():\n",
    "        for idx, (X, tgt) in tqdm(enumerate(train_dataloader)):\n",
    "            tgt_text = \" \"#tgt[\"text\"]\n",
    "            tgt_class = tgt[\"label\"].long().to(device)\n",
    "            tgt_class = F.one_hot(tgt_class, num_classes=5)\n",
    "            one_hots = ukr_lang_chars_handle.sentences_to_one_hots(tgt_text, 152).to(device)\n",
    "            X = X.to(device)\n",
    "            emb, output = model(X, one_hots)\n",
    "            A = torch.argmax(output, dim=-1)\n",
    "            B = torch.argmax(tgt_class, dim=-1)\n",
    "            is_right = (A == B)\n",
    "            positive += torch.sum(is_right)\n",
    "\n",
    "    train_accuracy = positive / train_len\n",
    "    if wb:\n",
    "        wb.log({\n",
    "            \"train accuracy\": train_accuracy,\n",
    "            \"epoch\": epoch\n",
    "        })\n",
    "    print(f\"Accuracy on TRAIN dataset: {train_accuracy*100:.2f}%\\n\")\n",
    "\n",
    "\n",
    "def get_scheduler(epochs, train_len, optimizer, scheduler_name=\"cosine_with_warmup\"):\n",
    "    wandb.config[\"scheduler\"] = scheduler_name\n",
    "    if scheduler_name == \"cosine_with_warmup\":\n",
    "        return get_cosine_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=epochs//5,\n",
    "                                                num_training_steps=epochs - epochs//5,\n",
    "                                                num_cycles=1.25)\n",
    "    elif scheduler_name == \"constant\":\n",
    "        return torch.optim.lr_scheduler.ConstantLR(optimizer)\n",
    "    elif scheduler_name == \"exponential\":\n",
    "        return torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
    "    elif scheduler_name == \"one_circle\":\n",
    "        return OneCycleLR(optimizer,\n",
    "                          max_lr=CONFIG[\"learning_rate\"]*10,\n",
    "                          total_steps=train_len)\n",
    "\n",
    "\n",
    "def main():\n",
    "    #wandb_stat = wandb.init(project=\"ASR\", entity=\"Alex2135\", config=CONFIG)\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    # Making dataset and loader\n",
    "    ds = CommonVoiceUkr(TRAIN_PATH, TRAIN_SPEC_PATH, batch_size=BATCH_SIZE)\n",
    "    train_dataloader = DataLoader(ds, shuffle=True, batch_size=BATCH_SIZE)\n",
    "    train_val_dataloader = DataLoader(ds, shuffle=True, batch_size=64)\n",
    "    epochs = CONFIG[\"epochs\"]\n",
    "    train_len = len(train_dataloader) * epochs\n",
    "\n",
    "    tgt_n = 152\n",
    "    model = Model(n_encoders=CONFIG[\"n_encoders\"], n_decoders=CONFIG[\"n_decoders\"], device=device)\n",
    "    if CONFIG[\"pretrain\"] == True:\n",
    "        PATH = os.path.join(DATA_DIR, \"model_1.pt\")\n",
    "        model = Model(n_encoders=CONFIG[\"n_encoders\"], n_decoders=CONFIG[\"n_decoders\"], device=device)\n",
    "        model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    # Create optimizator\n",
    "    optimizer = AdamW(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "    save_model = True\n",
    "    scheduler = get_scheduler(CONFIG[\"epochs\"], train_len, optimizer, \"cosine_with_warmup\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch №{epoch}\")\n",
    "        train(model, train_dataloader, optimizer, device, scheduler=scheduler, epoch=epoch)#, wb=wandb_stat)\n",
    "        val(model, train_val_dataloader, device, epoch)#, wb=wandb_stat)\n",
    "        scheduler.step(epoch)\n",
    "        #wandb.log({\"scheduler lr\": scheduler.get_last_lr()[0]})\n",
    "\n",
    "    if save_model:\n",
    "        PATH = os.path.join(DATA_DIR, \"model_1.pt\")\n",
    "        print(f\"Save model to path: '{PATH}'\")\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bba92347-6de7-44e9-b51b-de667b4aacfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(89, 64)\n",
    "out = torch.mean(X, dim=-2)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6892e123-6475-460c-941a-325b9915c839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import Conformer as con\n",
    "from data_processing import ukr_lang_chars_handle\n",
    "from data_processing import CommonVoiceUkr\n",
    "from config import *\n",
    "from torch.optim import RAdam, AdamW\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import numpy as np\n",
    "#from torch.optim.lr_scheduler import MultiplicativeLR\n",
    "from model import MaskedSoftmaxCELoss\n",
    "from model import get_cosine_schedule_with_warmup\n",
    "import wandb\n",
    "\n",
    "# wandb.init(project=\"ASR\", entity=\"alex2135\")\n",
    "\n",
    "# wandb.config = CONFIG\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Making dataset and loader\n",
    "ds = CommonVoiceUkr(TRAIN_PATH, TRAIN_SPEC_PATH, batch_size=BATCH_SIZE)\n",
    "train_dataloader = DataLoader(ds, shuffle=True, batch_size=BATCH_SIZE)\n",
    "train_len = len(train_dataloader) * CONFIG[\"epochs\"]\n",
    "print(\"train len:\", train_len)\n",
    "\n",
    "def eleminate_channels(X: torch.Tensor) -> torch.Tensor:\n",
    "    b, c, h, w = X.shape\n",
    "    X = X.view(b, c*h, w)\n",
    "    return X\n",
    "\n",
    "tgt_n = 152\n",
    "model = con(n_encoders=CONFIG[\"n_encoders\"], n_decoders=CONFIG[\"n_decoders\"], device=device)\n",
    "if CONFIG[\"pretrain\"] == True:\n",
    "    PATH = os.path.join(DATA_DIR, \"model_1.pt\")\n",
    "    model = con(n_encoders=CONFIG[\"n_encoders\"], n_decoders=CONFIG[\"n_decoders\"], device=device)\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# Create optimizator\n",
    "optimizer = AdamW(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=train_len//5, num_training_steps=train_len)\n",
    "\n",
    "# Create CTC criterion\n",
    "alpha_loss = torch.Tensor([0.7]).to(device)\n",
    "ctc_criterion = nn.CTCLoss(blank=ukr_lang_chars_handle.token_to_index[\"<blank>\"], zero_infinity=True)\n",
    "ce_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "running_loss = []\n",
    "losses_per_phase = []\n",
    "epochs = CONFIG[\"epochs\"]\n",
    "try:\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch №{epoch}\")\n",
    "        for idx, (X, tgt) in tqdm(enumerate(train_dataloader)):\n",
    "\n",
    "            tgt_text = tgt[\"text\"]\n",
    "            tgt_class = tgt[\"label\"]\n",
    "\n",
    "            one_hots = ukr_lang_chars_handle.sentences_to_one_hots(tgt_text, 152).to(device)\n",
    "            X = X.to(device) #\n",
    "\n",
    "            emb, output = model(X, one_hots)  # (batch, _, n_class, time), (batch, _, time, n_class)\n",
    "            b, cnls, t, clss = output.shape\n",
    "            output = output.view(t * cnls, b, clss)  # (time, batch, n_class)\n",
    "            output = F.log_softmax(output, dim=-1)\n",
    "            indeces = ukr_lang_chars_handle.sentences_to_indeces(tgt_text).to(device)\n",
    "\n",
    "            input_lengths = torch.full(size=(BATCH_SIZE,), fill_value=t, dtype=torch.long).to(device)\n",
    "            target_lengths = torch.full(size=(BATCH_SIZE,), fill_value=indeces.shape[-1], dtype=torch.long).to(device)\n",
    "            ctc_loss = ctc_criterion(output.to(device), indeces, input_lengths, target_lengths)\n",
    "\n",
    "            print(f\"{output.shape=}\")\n",
    "            break\n",
    "            #print(f\"\\n{emb.shape=}\\n{one_hots.shape=}\")\n",
    "            #emb, one_hots = eleminate_channels(emb.to(device)), eleminate_channels(one_hots.float())\n",
    "            #ce_loss = ce_criterion(emb, one_hots)\n",
    "\n",
    "            #loss = alpha_loss * torch.log(ce_loss) + (1-alpha_loss) * torch.log(ctc_loss)\n",
    "            loss = ctc_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            #print(f\"\\n{ctc_loss.item()=}, {torch.log(ctc_loss)}\\n{ce_loss.item()=}, {torch.log(ce_loss)}\")\n",
    "            running_loss.append(loss.cpu().detach().numpy())\n",
    "            losses_per_phase.append(loss.cpu().detach().numpy())\n",
    "            # wandb.log({\"loss\": loss})\n",
    "\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(\"Target label:\", tgt)\n",
    "                print(\"Running loss:\")\n",
    "                pprint.pprint(running_loss)\n",
    "                print(output.shape)\n",
    "                print(\"Is nan in output:\", torch.sum(torch.isnan(output)))\n",
    "                print(\"Is inf in output:\", torch.sum(torch.isinf(output)))\n",
    "                pprint.pprint(output)\n",
    "                break\n",
    "            if (idx + 1) % 50 == 0:  # print every 200 mini-batches\n",
    "                print(f\"Epoch: {epoch}, Last loss: {loss.item():.4f}, Loss phase mean: {np.mean(np.array(losses_per_phase)):.4f}\")\n",
    "                losses_per_phase = []\n",
    "            optimizer.zero_grad()\n",
    "    import os\n",
    "    PATH = os.path.join(DATA_DIR, \"model_1.pt\")\n",
    "    print(PATH)\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa66b6d9-683a-4354-952a-33c42d3467cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59821272-9f3f-408f-b527-992fb62a6222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[[-4.3921, -2.7748, -2.6272, -3.1844, -5.8391, -2.9118, -1.5081,\n",
      "          -2.0204, -2.4960, -4.6648, -3.1822, -5.2760, -4.1566, -5.2143,\n",
      "          -3.3396, -3.1048, -4.1634, -2.6075, -3.3762, -3.2947]],\n",
      "\n",
      "        [[-3.9547, -3.0358, -3.1015, -4.6223, -4.6874, -1.6695, -3.2782,\n",
      "          -3.1245, -2.7917, -3.6702, -6.2349, -3.0321, -2.4299, -2.5736,\n",
      "          -5.0681, -2.5046, -2.2475, -2.7110, -3.3705, -5.8073]]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "\n",
      "\n",
      "Targets: tensor([[ 1,  8, 16,  9,  7, 12,  1, 13, 10, 19,  6, 19, 17, 18, 18, 16,  1,  6,\n",
      "          2,  9,  5,  7,  8,  7, 11,  2, 14, 13,  7,  8]])\n",
      "Input lengths:\n",
      " tensor([50])\n",
      "Target lengths:\n",
      " tensor([18])\n"
     ]
    }
   ],
   "source": [
    "T = 50\n",
    "C = 20\n",
    "N = 1\n",
    "S = 30\n",
    "\n",
    "S_min = 10\n",
    "input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "print(\"Inputs:\", input[:2])\n",
    "\n",
    "target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n",
    "print(\"\\n\\nTargets:\", target[:2])\n",
    "\n",
    "input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "print(\"Input lengths:\\n\", input_lengths)\n",
    "\n",
    "target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)\n",
    "print(\"Target lengths:\\n\", target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca59d1f-7e79-4d4d-a4a5-04c1e2d34385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0059, -0.0455,  0.0040,  0.0023,  0.0002,  0.0030,  0.0123,\n",
       "           0.0074,  0.0046,  0.0005,  0.0023,  0.0003,  0.0009,  0.0003,\n",
       "           0.0020,  0.0025,  0.0009,  0.0041,  0.0019,  0.0021]],\n",
       "\n",
       "        [[-0.0091, -0.0255,  0.0025,  0.0005,  0.0005,  0.0105,  0.0021,\n",
       "           0.0024, -0.0138,  0.0014,  0.0001,  0.0027,  0.0049,  0.0042,\n",
       "           0.0003,  0.0045,  0.0059,  0.0037,  0.0019,  0.0002]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctc_loss = nn.CTCLoss()\n",
    "loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "loss.backward()\n",
    "input.grad[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8be60f-96c9-4025-8dac-b9f62f91c497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<blank>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3, ' ': 4, 'а': 5, 'б': 6, 'в': 7, 'г': 8, 'д': 9, 'е': 10, 'ж': 11, 'з': 12, 'и': 13, 'й': 14, 'к': 15, 'л': 16, 'м': 17, 'н': 18, 'о': 19, 'п': 20, 'р': 21, 'с': 22, 'т': 23, 'у': 24, 'ф': 25, 'х': 26, 'ц': 27, 'ч': 28, 'ш': 29, 'щ': 30, 'ь': 31, 'ю': 32, 'я': 33, 'є': 34, 'і': 35, 'ї': 36, 'ґ': 37}\n",
      "{0: '<blank>', 1: '<sos>', 2: '<eos>', 3: '<unk>', 4: ' ', 5: 'а', 6: 'б', 7: 'в', 8: 'г', 9: 'д', 10: 'е', 11: 'ж', 12: 'з', 13: 'и', 14: 'й', 15: 'к', 16: 'л', 17: 'м', 18: 'н', 19: 'о', 20: 'п', 21: 'р', 22: 'с', 23: 'т', 24: 'у', 25: 'ф', 26: 'х', 27: 'ц', 28: 'ч', 29: 'ш', 30: 'щ', 31: 'ь', 32: 'ю', 33: 'я', 34: 'є', 35: 'і', 36: 'ї', 37: 'ґ'}\n"
     ]
    }
   ],
   "source": [
    "extra_tokens = [\"<blank>\", \"<sos>\", \"<eos>\", \"<unk>\", \" \"]\n",
    "tokens = extra_tokens + ['а', 'б', 'в', 'г', 'д', \n",
    "        'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', \n",
    "        'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', \n",
    "        'х', 'ц', 'ч', 'ш', 'щ', 'ь', 'ю', 'я',\n",
    "        'є', 'і', 'ї', 'ґ']\n",
    "char_to_index = {c:i for i, c in enumerate(tokens)}\n",
    "index_to_char = {i:c for i, c in enumerate(tokens)}\n",
    "print(char_to_index)\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86c7d8c-a1f3-44e9-a370-48447b0a0b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence \n",
      "'Московитам дозволено створити свою державу а татарам чеченцям – ні Але це – расизм'\n",
      "to indeces:\n",
      "\n",
      "1 17 19 22 15 19 7 13 23 5 17 4 9 19 12 7 19 16 10 18 19 4 22 23 7 19 21 13 23 13 4 22 7 19 32 4 9 10 21 11 5 7 24 4 5 4 23 5 23 5 21 5 17 4 28 10 28 10 18 27 33 17 4 18 35 4 5 16 10 4 27 10 4 21 5 22 13 12 17 2 \n",
      "\n",
      "Sentence \n",
      "'Московитам дозволено створити свою державу а татарам чеченцям – ні Але це – расизм'\n",
      "from indeces to chars:\n",
      "\n",
      "<sos> м о с к о в и т а м   д о з в о л е н о   с т в о р и т и   с в о ю   д е р ж а в у   а   т а т а р а м   ч е ч е н ц я м   н і   а л е   ц е   р а с и з м <eos> "
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def remove_stop_signs(sentence):\n",
    "    stop_signs = string.punctuation + \"–—»«…“”’\"\n",
    "    for sign in stop_signs:\n",
    "        sentence = sentence.replace(sign, \"\")\n",
    "    return sentence\n",
    "\n",
    "def sentence_to_indeces(sentence, cti : dict):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        cti - char to index dictionary\n",
    "    \"\"\"\n",
    "    sent = remove_stop_signs(sentence)\n",
    "    sent = sent.lower()\n",
    "    sent = sent.split()\n",
    "    result = []\n",
    "    for word in sent:\n",
    "        for c in word:\n",
    "            result.append(cti.get(c, cti[\"<unk>\"]))\n",
    "        result.append(cti[\" \"])\n",
    "    result = result[:-1]\n",
    "    result = [cti[\"<sos>\"]] + result + [cti[\"<eos>\"]]\n",
    "    return result\n",
    "\n",
    "\n",
    "sent = \"Московитам дозволено створити свою державу а татарам чеченцям – ні Але це – расизм\"\n",
    "sent_to_idxs = sentence_to_indeces(sent, char_to_index)\n",
    "print(f\"Sentence \\n'{sent}'\\nto indeces:\\n\")\n",
    "for i in sent_to_idxs:\n",
    "    print(i, end=\" \")\n",
    "\n",
    "print(f\"\\n\\nSentence \\n'{sent}'\\nfrom indeces to chars:\\n\")\n",
    "for i in sent_to_idxs:\n",
    "    print(index_to_char[i], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb4b99c-d8a2-44a7-b16c-6bee91f642c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"D:\\\\ML\\\\Speech recognition\\\\NLP_diploma\\\\uk\"\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436b932a-c5ec-4ef0-914d-965cb9b11790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max symbols 137\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "is_show_prints = False\n",
    "for sent in train_df[\"sentence\"]:\n",
    "    sent_to_idxs = sentence_to_indeces(sent, char_to_index)\n",
    "    if len(sent_to_idxs) > max:\n",
    "        max = len(sent_to_idxs)    \n",
    "    \n",
    "    if is_show_prints:\n",
    "        print(f\"Sentence \\n'{sent}'\\nto indeces:\")\n",
    "        for i in sent_to_idxs:\n",
    "            print(i, end=\" \")\n",
    "        print(f\"\\n\\nfrom indeces to chars:\")\n",
    "        for i in sent_to_idxs:\n",
    "            print(index_to_char[i], end=\" \")\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        \n",
    "print(f\"Max symbols {max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b787ba5-da22-4a74-b748-6f9f1d8ded9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 152)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens), 152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a41aafa1-e953-4fb1-96d9-552c9d5a7ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER PARAMS\n",
    "# Encoder inputs\n",
    "enc_n_feats = 256   # spectrogram height\n",
    "enc_d_model = 1024  # spectrogram max width\n",
    "\n",
    "# DECODER PARAMS\n",
    "# Decoder inputs\n",
    "dec_n_feats = 38    # len(tokens)\n",
    "dec_d_model = 152   # maximum symbols in sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a1e4bf1-1291-4d52-9d2c-131a1788b5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic: 'Московитам дозволено створити свою державу а татарам чеченцям – ні Але це – расизм'\n",
      "idxs_to_onehot result:\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n",
      "(80, 38)\n",
      "\n",
      "onehot_matrix_to_idxs result:\n",
      "<sos> м о с к о в и т а м   д о з в о л е н о   с т в о р и т и   с в о ю   д е р ж а в у   а   т а т а р а м   ч е ч е н ц я м   н і   а л е   ц е   р а с и з м <eos> "
     ]
    }
   ],
   "source": [
    "def idxs_to_onehot(sent_idxs, length:int):\n",
    "    result = []\n",
    "    for number in sent_idxs:\n",
    "        onehot = np.zeros((length,))\n",
    "        onehot[number] = 1\n",
    "        result.append(onehot)\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "def onehot_matrix_to_idxs(onehots):\n",
    "    result = []\n",
    "    for i in range(onehots.shape[0]):\n",
    "        onehot = onehots[i, :]\n",
    "        number = np.argmax(onehot)\n",
    "        result.append(number)\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "sent = \"Московитам дозволено створити свою державу а татарам чеченцям – ні Але це – расизм\"\n",
    "print(f\"Basic: '{sent}'\")\n",
    "\n",
    "sent_to_idxs = sentence_to_indeces(sent, char_to_index)\n",
    "a = idxs_to_onehot(sent_to_idxs, dec_n_feats)\n",
    "print(\"idxs_to_onehot result:\")\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n",
    "print(\"\\nonehot_matrix_to_idxs result:\")\n",
    "r = onehot_matrix_to_idxs(a)\n",
    "for i in r:\n",
    "    print(index_to_char[i], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc699f-bba9-494a-b2be-e851745245a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

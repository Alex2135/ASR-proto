{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6acf0168-e013-4858-9405-64820c95b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98cc836a-3ee4-4376-a950-9ca8e6b692c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import Conformer as con\n",
    "from data_processing import ukr_lang_chars_handle\n",
    "from data_processing import CommonVoiceUkr\n",
    "from model.conformer import Conformer as con\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a97b1-22b2-427c-b42e-9e4a148a3029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230cc976-c2c4-4f64-8680-8dd486f717a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "input lengths: tensor([256])\n",
      "torch.Size([1])\n",
      "target lengths: tensor([152])\n"
     ]
    }
   ],
   "source": [
    "target = torch.randn(1, 152) # (N, S) where N =batch size and S = max target length \n",
    "\n",
    "outputs = torch.randn(1, 1, 256, 38) # Tensor of size (T, N, C), where T = input length, N = batch size, and C = number of classes (including blank)\n",
    "b, cnls, t, clss = outputs.shape\n",
    "outputs = outputs.view(t*cnls, b, clss)\n",
    "\n",
    "\n",
    "input_lengths = torch.full(size=(1,), fill_value=outputs.shape[0], dtype=torch.long)\n",
    "target_lengths = torch.full(size=(1,), fill_value=target.shape[1], dtype=torch.long)\n",
    "print(input_lengths.shape)\n",
    "print(\"input lengths:\", input_lengths)\n",
    "\n",
    "print(target_lengths.shape)\n",
    "print(\"target lengths:\", target_lengths)\n",
    "\n",
    "ctc_loss = nn.CTCLoss(zero_infinity=False, reduction=\"none\")\n",
    "loss = ctc_loss(outputs, target, input_lengths, target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f297384-002d-4594-b1ce-e487360552bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape: torch.Size([1, 1, 256, 38])\n",
      "torch.Size([2, 1, 256, 1024]) ('Поставився грибом, лізь у кошіль.', 'Після надцятого разу дід скошує очі до онука і питає: “Що, усi?”')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6748/2618398850.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mone_hots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mukr_lang_chars_handle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences_to_one_hots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hots\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ML\\Speech recognition\\NLP_diploma\\ASR proto\\ASR proto\\data_processing\\sentence_handling.py\u001b[0m in \u001b[0;36msentences_to_one_hots\u001b[1;34m(self, sents)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentence_to_one_hots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mone_hots_to_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hots\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "from data_processing import ukr_lang_chars_handle\n",
    "\n",
    "src = torch.rand(1, 1, 256, 1024)\n",
    "tgt = torch.rand(1, 1, 38, 152)\n",
    "\n",
    "model = con()\n",
    "result = model(src, tgt)\n",
    "\n",
    "ds = CommonVoiceUkr(TRAIN_PATH, TRAIN_SPEC_PATH)\n",
    "train_dataloader = DataLoader(ds, shuffle=True, batch_size=2)\n",
    "\n",
    "for X, tgt in train_dataloader:\n",
    "    print(X.shape, tgt)\n",
    "    \n",
    "    one_hots = ukr_lang_chars_handle.sentences_to_one_hots(tgt)\n",
    "    print(one_hots.shape)\n",
    "    \n",
    "    #y = model(X, tgt)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d49e42d2-cb84-45f0-b099-447e7a86958d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6748/4078590462.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 1"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[1, 2], [3, 4]])\n",
    "b = torch.Tensor([5, 6])\n",
    "\n",
    "torch.cat((a, b), dim=0)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b7687-d357-4c05-9275-fb4b8cbe92d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e632c1a4-71d0-4f2a-8058-363ecb2dae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import Conformer as con\n",
    "from data_processing import ukr_lang_chars_handle\n",
    "from data_processing import CommonVoiceUkr\n",
    "from model.conformer import Conformer as con\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230cc976-c2c4-4f64-8680-8dd486f717a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "input lengths: tensor([256])\n",
      "torch.Size([1])\n",
      "target lengths: tensor([152])\n"
     ]
    }
   ],
   "source": [
    "tgt_n = 152\n",
    "target = torch.randn(BATCH_SIZE, tgt_n) # (N, S) where N =batch size and S = max target length \n",
    "\n",
    "outputs = torch.randn(BATCH_SIZE, 1, 256, 38) # Tensor of size (T, N, C), where T = input length, N = batch size, and C = number of classes (including blank)\n",
    "b, cnls, t, clss = outputs.shape\n",
    "outputs = outputs.view(t*cnls, b, clss)\n",
    "\n",
    "\n",
    "input_lengths = torch.full(size=(BATCH_SIZE,), fill_value=outputs.shape[0], dtype=torch.long)\n",
    "target_lengths = torch.full(size=(BATCH_SIZE,), fill_value=target.shape[-1], dtype=torch.long)\n",
    "print(input_lengths.shape)\n",
    "print(\"input lengths:\", input_lengths)\n",
    "\n",
    "print(target_lengths.shape)\n",
    "print(\"target lengths:\", target_lengths)\n",
    "\n",
    "ctc_loss = nn.CTCLoss(zero_infinity=False, reduction=\"none\")\n",
    "loss = ctc_loss(outputs, target, input_lengths, target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c02c55-2237-4a30-ac5e-8fcf9f5d3245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(BATCH_SIZE)\n",
    "ds = CommonVoiceUkr(TRAIN_PATH, TRAIN_SPEC_PATH)\n",
    "n_ds = len(ds)\n",
    "n_ds = n_ds - n_ds % BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46ad63d5-44fa-4589-8cb8-85cfaba74ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 400\n",
      "Epoch №1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb.shape=torch.Size([1, 1, 38, 152])\n",
      "output.shape=torch.Size([256, 1, 38])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import Conformer as con\n",
    "from data_processing import ukr_lang_chars_handle\n",
    "from data_processing import CommonVoiceUkr\n",
    "from config import *\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from model import get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Making dataset and loader\n",
    "ds = CommonVoiceUkr(TRAIN_PATH, TRAIN_SPEC_PATH, batch_size=BATCH_SIZE)\n",
    "train_dataloader = DataLoader(ds, shuffle=True, batch_size=BATCH_SIZE)\n",
    "train_len = len(train_dataloader) * CONFIG[\"epochs\"]\n",
    "print(\"train len:\", train_len)\n",
    "\n",
    "def eleminate_channels(X: torch.Tensor) -> torch.Tensor:\n",
    "    b, c, h, w = X.shape\n",
    "    X = X.view(b, c*h, w)\n",
    "    return X\n",
    "\n",
    "tgt_n = 152\n",
    "model = con(n_encoders=CONFIG[\"n_encoders\"], n_decoders=CONFIG[\"n_decoders\"], device=device)\n",
    "if CONFIG[\"pretrain\"] == True:\n",
    "    PATH = os.path.join(DATA_DIR, \"model_1.pt\")\n",
    "    model = con(n_encoders=CONFIG[\"n_encoders\"], n_decoders=CONFIG[\"n_decoders\"], device=device)\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# Create optimizator\n",
    "optimizer = AdamW(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=train_len//5, num_training_steps=train_len)\n",
    "\n",
    "# Create CE criterion\n",
    "ce_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "running_loss = []\n",
    "losses_per_phase = []\n",
    "epochs = CONFIG[\"epochs\"]\n",
    "save_model = False\n",
    "try:\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch №{epoch}\")\n",
    "        for idx, (X, tgt) in tqdm(enumerate(train_dataloader)):\n",
    "            tgt_text = tgt[\"text\"]\n",
    "            tgt_class = torch.Tensor([tgt[\"label\"]]).long().to(device)\n",
    "            tgt_class = F.one_hot(tgt_class)\n",
    "\n",
    "            one_hots = ukr_lang_chars_handle.sentences_to_one_hots(tgt_text, 152).to(device)\n",
    "            X = X.to(device) #\n",
    "\n",
    "            emb, output = model(X, one_hots)  # (batch, _, n_class, time), (batch, _, time, n_class)\n",
    "            output = torch.squeeze(output, 1).permute(1, 0, 2)  # (time, batch, n_class)\n",
    "\n",
    "            print(f\"{emb.shape=}\")\n",
    "            print(f\"{output.shape=}\")\n",
    "            break\n",
    "            loss = ce_criterion(output) # output.shape == (N, C) where N - batch, C - number of classes\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss.append(loss.cpu().detach().numpy())\n",
    "            losses_per_phase.append(loss.cpu().detach().numpy())\n",
    "            # wandb.log({\"loss\": loss})\n",
    "\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(\"Target label:\", tgt)\n",
    "                print(\"Running loss:\")\n",
    "                pprint.pprint(running_loss)\n",
    "                print(output.shape)\n",
    "                print(\"Is nan in output:\", torch.sum(torch.isnan(output)))\n",
    "                print(\"Is inf in output:\", torch.sum(torch.isinf(output)))\n",
    "                pprint.pprint(output)\n",
    "                break\n",
    "            if (idx + 1) % 50 == 0:  # print every 200 mini-batches\n",
    "                print(f\"Epoch: {epoch}, Last loss: {loss.item():.4f}, Loss phase mean: {np.mean(np.array(losses_per_phase)):.4f}\")\n",
    "                losses_per_phase = []\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    if save_model:\n",
    "        import os\n",
    "        PATH = os.path.join(DATA_DIR, \"model_1.pt\")\n",
    "        print(PATH)\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826bb23d-afe3-48ef-8721-58b81b20ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "losses_list = [t.cpu().detach().numpy() if type(t) is torch.Tensor else t for t in running_loss ]\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.plot(losses_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3e7aa3-53f5-44c2-baac-7bcb63a4f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wtout_zeros = np.array([t.cpu().detach().numpy() if type(t) is torch.Tensor else t for t in running_loss])\n",
    "print(len(running_loss))\n",
    "wtout_zeros = wtout_zeros[wtout_zeros != 0]\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.plot(wtout_zeros)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6bc36b-e045-44ee-ad64-f1d3fa236967",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "PATH = os.path.join(DATA_DIR, \"model_1.pt\")\n",
    "model = con(device=device)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f735e-fe53-4be6-b905-a2626df9ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeff538-a4b8-448a-8aa0-080043beb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = (\"Привіт\",)\n",
    "oh_sent = ukr_lang_chars_handle.sentences_to_one_hots(tgt, 152)\n",
    "#print(oh_sent)\n",
    "\n",
    "result = ukr_lang_chars_handle.one_hots_to_sentence(oh_sent)\n",
    "#print(result)\n",
    "indeces = ukr_lang_chars_handle.sentence_to_indeces(sent[0])\n",
    "#print(indeces)\n",
    "\n",
    "one_hots = F.one_hot(torch.Tensor(indeces).long(), num_classes=38)\n",
    "#print(one_hots)\n",
    "\n",
    "reproduced_sent = ukr_lang_chars_handle.onehot_matrix_to_idxs(one_hots)\n",
    "#print(f\"{reproduced_sent=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe5b77-258f-4f60-93e3-0e4e443cb874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from data_processing import ukr_lang_chars_handle\n",
    "from config import *\n",
    "from model import Conformer as con\n",
    "from data_processing import CommonVoiceUkr\n",
    "from torch.utils.data import DataLoader\n",
    "import pprint\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "PATH = os.path.join(DATA_DIR, \"model_2.pt\")\n",
    "model = con(n_encoders=8, n_decoders=8, device=device)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "model.eval()\n",
    "ds = CommonVoiceUkr(TRAIN_PATH, TRAIN_SPEC_PATH)\n",
    "train_dataloader = DataLoader(ds, shuffle=True, batch_size=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    X, tgt = next(iter(train_dataloader))\n",
    "    X = X.to(device)\n",
    "    print(\"Target:\", tgt)\n",
    "    print(\"X shape:\", X.shape)\n",
    "    #tgt = (\"\",)\n",
    "\n",
    "    tgt_one_hots = ukr_lang_chars_handle.sentences_to_one_hots(tgt, 152)\n",
    "    print(\"tgt to one_hots shape:\", tgt_one_hots.shape)\n",
    "    print(\"tgt to one_hots:\", ukr_lang_chars_handle.one_hots_to_sentences(tgt_one_hots))\n",
    "\n",
    "    out_data = model(X, tgt_one_hots.to(device))\n",
    "    out_data = F.softmax(out_data, dim=-1)\n",
    "    out_data = out_data.cpu()\n",
    "    print(\"\\n\\nOutput data shape:\", out_data.shape)\n",
    "    print(\"output:\", out_data)\n",
    "    out_data = out_data.transpose(-1, -2).contiguous()\n",
    "    result = ukr_lang_chars_handle.one_hots_to_sentences(out_data)\n",
    "    pprint.pprint(len(result))\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35493a22-eba4-4223-8119-c3a153af1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PATH = os.path.join(DATA_DIR, \"model_1.pt\")\n",
    "print(PATH)\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78cf4bc-8d33-4ce6-af74-24cf5c65875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 6\n",
    "\n",
    "A = torch.randn(2, 1, 64, 256)\n",
    "As = A.repeat(1, 6, 1, 1).transpose(-1, -2).contiguous()\n",
    "As.shape\n",
    "#torch.stack(A, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2584cb-df35-4743-bcdc-5458ed30ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(2, 1, 64, 256)\n",
    "\n",
    "norm = nn.LayerNorm(256)\n",
    "norm(A).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156dcbf-68df-4aa2-ac16-ba2299719ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MaskedSoftmaxCELoss\n",
    "\n",
    "\n",
    "X = torch.randn(8, 1, 64, 256)\n",
    "X = torch.squeeze(X, 1)\n",
    "lin1 = nn.Linear(256, 152)\n",
    "lin2 = nn.Linear(64, 38)\n",
    "X = lin1(X)\n",
    "X = lin2(X.transpose(-1, -2).contiguous())\n",
    "X = X.transpose(-1, -2).contiguous()\n",
    "print(X.shape)\n",
    "\n",
    "oh = torch.randn(8, 1, 38, 152)\n",
    "oh = eleminate_channels(oh)\n",
    "\n",
    "\n",
    "ce_criterion = MaskedSoftmaxCELoss()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "loss(X, oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8067caf7-ab30-481e-b682-dff8bdbd3541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin1 = nn.Sequential(nn.Linear(38*256, 2048), nn.ReLU())\n",
    "lin2 = nn.Sequential(nn.Linear(2048, 1024), nn.ReLU())\n",
    "lin3 = nn.Sequential(nn.Linear(1024, 5), nn.Softmax(dim=-1))\n",
    "\n",
    "X = torch.randn([256, 1, 38])\n",
    "t, b, d = X.shape\n",
    "X = X.view(b, t*d)\n",
    "\n",
    "X = lin1(X)\n",
    "X = lin2(X)\n",
    "X = lin3(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe15a8-2637-49fa-9b2f-186b9ff0ff42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
